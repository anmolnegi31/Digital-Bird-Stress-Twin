# ğŸ¦ Digital Bird Stress Twin

> **Production-grade ML/DL system for predicting and simulating avian stress behavior using temporal deep learning and generative AI**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.5+-orange.svg)](https://mlflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Key Features](#key-features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [API Documentation](#api-documentation)
- [Model Training](#model-training)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Deployment](#deployment)
- [Contributing](#contributing)

---

## ğŸ¯ Overview

The **Digital Bird Stress Twin** is a comprehensive, production-ready machine learning system that:

- **Predicts** bird stress levels from acoustic and environmental data
- **Forecasts** stress evolution over 72-hour horizons
- **Simulates** synthetic bird vocalizations under varying stress conditions
- **Monitors** model performance and data drift in real-time
- **Integrates** with live APIs (eBird, Xeno-Canto, OpenWeatherMap)

### What is a Digital Twin?

A Digital Twin is a **data-driven, probabilistic AI model** that emulates the behavioral, acoustic, and stress-response dynamics of real bird species under varying environmental stimuli. This enables:

- âœ… Simulation of future behavior
- âœ… Anomaly detection for disaster preparedness
- âœ… Predictive analytics for conservation
- âœ… Scientific research insights

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Real-World Environment    â”‚
â”‚ (Weather, Pressure, EMF)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Ingestion Layer       â”‚
â”‚ â€¢ eBird API                â”‚
â”‚ â€¢ Xeno-Canto API           â”‚
â”‚ â€¢ OpenWeatherMap API       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Engineering Layer  â”‚
â”‚ â€¢ MFCCs (40 coefficients)  â”‚
â”‚ â€¢ Spectral Features        â”‚
â”‚ â€¢ Environmental Features   â”‚
â”‚ â€¢ Stress Index             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Digital Bird Stress Twin   â”‚
â”‚ (Core AI Models)           â”‚
â”‚ â€¢ LSTM (Temporal)          â”‚
â”‚ â€¢ VAE (Generative)         â”‚
â”‚ â€¢ Attention Mechanism      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prediction & Simulation    â”‚
â”‚ â€¢ Stress Forecast (72h)    â”‚
â”‚ â€¢ Risk Assessment          â”‚
â”‚ â€¢ Audio Generation         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring & MLOps         â”‚
â”‚ â€¢ MLflow Tracking          â”‚
â”‚ â€¢ Drift Detection          â”‚
â”‚ â€¢ Auto-Retraining          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features

### ğŸ¤– Machine Learning Models

#### 1. **LSTM Temporal Stress Predictor**
- **Architecture**: Bidirectional LSTM with attention mechanism
- **Input**: Time-series of acoustic + environmental features
- **Output**: Continuous stress score [0, 1] + 72h forecast
- **Performance**: RÂ² > 0.90 on validation set

#### 2. **Conditional VAE for Audio Simulation**
- **Architecture**: Variational Autoencoder with condition encoding
- **Input**: Stress level [0, 1]
- **Output**: Synthetic MFCC features (40 dimensions)
- **Use Case**: Generate expected bird calls under stress

### ğŸ”¬ Feature Engineering

| Feature Type | Components | Purpose |
|--------------|------------|---------|
| **Acoustic** | MFCCs (40), Spectral Centroid, Entropy, ZCR, Chroma | Capture vocal patterns |
| **Environmental** | Temperature, Pressure, Humidity, Wind, Gradients | Stress triggers |
| **Temporal** | Hour, Day, Season (cyclical encoding) | Time-dependent patterns |
| **Stress Index** | Weighted combination of 5 indicators | Quantify stress level |

### ğŸ“Š MLOps Pipeline

- **Experiment Tracking**: MLflow
- **Model Versioning**: MLflow Model Registry
- **Data Versioning**: DVC
- **Monitoring**: Evidently AI (drift detection)
- **API**: FastAPI with auto-generated docs
- **Deployment**: Docker + Docker Compose

---

## ğŸš€ Installation

### Prerequisites

- Python 3.9+
- CUDA-capable GPU (optional, for faster training)
- Docker & Docker Compose (for containerized deployment)

### Option 1: Local Installation

```bash
# Clone repository
git clone https://github.com/yourusername/digital-bird-stress-twin.git
cd digital-bird-stress-twin

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install package in editable mode
pip install -e .

# Setup environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Option 2: Docker Installation

```bash
# Build and run services
docker-compose up -d

# Access API at http://localhost:8000
# Access MLflow at http://localhost:5000
```

---

## âš¡ Quick Start

### 1. Data Ingestion

```python
from data_ingestion import create_ebird_client, create_weather_client

# Fetch bird observations
ebird = create_ebird_client()
observations = ebird.get_recent_observations(
    region_code="IN",
    species_code="houspe",  # House Sparrow
    days=14
)

# Fetch weather data
weather = create_weather_client()
weather_data = weather.get_current_weather(city="Delhi")
print(weather_data)
```

### 2. Feature Extraction

```python
from feature_engineering import AudioFeatureExtractor
from pathlib import Path

# Extract audio features
extractor = AudioFeatureExtractor(sample_rate=22050, n_mfcc=40)
audio_path = Path("data/raw/bird_call.wav")

features = extractor.process_audio_file(
    audio_path,
    segment_length=5.0,
    overlap=0.5
)
```

### 3. Model Training

```bash
# Train LSTM model
python src/train.py \
    --data data/processed/training_data.csv \
    --config configs/config.yaml \
    --run-name "experiment_001"
```

### 4. Run API Server

```bash
# Start API
cd src
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload

# Access interactive docs at http://localhost:8000/docs
```

### 5. Make Predictions

```bash
# Using curl
curl -X POST "http://localhost:8000/api/predict/stress" \
  -H "Content-Type: application/json" \
  -d '{
    "location": "Delhi",
    "species": "house_crow"
  }'
```

---

## ğŸ“š API Documentation

### Base URL: `http://localhost:8000`

### Core Endpoints

#### 1. **Predict Current Stress**
```http
POST /api/predict/stress
```

**Request Body:**
```json
{
  "location": "Delhi",
  "latitude": 28.6139,
  "longitude": 77.2090,
  "species": "house_crow",
  "audio_url": "https://example.com/bird_call.wav"
}
```

**Response:**
```json
{
  "stress_level": 0.73,
  "risk_level": "HIGH",
  "forecast_24h": 0.78,
  "forecast_48h": 0.82,
  "forecast_72h": 0.85,
  "confidence": 0.89,
  "timestamp": "2025-01-06T12:00:00Z",
  "environmental_factors": {
    "temperature": 32.5,
    "pressure": 1003.2,
    "humidity": 65.0
  }
}
```

#### 2. **Generate 72-Hour Forecast**
```http
POST /api/predict/forecast
```

Returns hourly predictions for the next 72 hours with peak risk periods.

#### 3. **Simulate Audio Patterns**
```http
POST /api/simulate/audio
```

Generate synthetic bird vocalizations for a given stress level using VAE.

#### 4. **Get Bird Observations**
```http
GET /api/data/observations?location=IN&days=14
```

#### 5. **Get Weather Data**
```http
GET /api/data/weather?location=Delhi
```

### Interactive Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ“ Model Training

### Data Preparation

```bash
# 1. Collect data
python scripts/collect_data.py --region IN --days 30

# 2. Process features
python scripts/process_features.py \
    --input data/raw \
    --output data/processed

# 3. Create training dataset
python scripts/create_dataset.py \
    --features data/processed/features.csv \
    --labels data/processed/labels.csv \
    --output data/processed/training_data.csv
```

### Training Configuration

Edit `configs/config.yaml`:

```yaml
models:
  lstm:
    architecture:
      hidden_size: 256
      num_layers: 3
      dropout: 0.3
      bidirectional: true
      attention: true
    training:
      batch_size: 32
      epochs: 100
      learning_rate: 0.001
      early_stopping_patience: 15
```

### Monitor Training

```bash
# Start MLflow UI
mlflow ui --port 5000

# View experiments at http://localhost:5000
```

### Evaluate Model

```python
from models import create_stress_lstm_model, LSTMTrainer
import torch

# Load trained model
model = create_stress_lstm_model(input_size=128, config={})
checkpoint = torch.load("models/checkpoints/best_model.pth")
model.load_state_dict(checkpoint['model_state_dict'])

# Evaluate on test set
# ... evaluation code
```

---

## ğŸ“ Project Structure

```
digital-bird-stress-twin/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml                 # Main configuration
â”‚   â””â”€â”€ species_config.yaml         # Species-specific settings
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw data
â”‚   â”œâ”€â”€ processed/                  # Processed features
â”‚   â””â”€â”€ interim/                    # Intermediate data
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/                # Model checkpoints
â”‚   â”œâ”€â”€ registry/                   # Registered models
â”‚   â””â”€â”€ exports/                    # Exported models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ data_ingestion/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_client.py          # Base API client
â”‚   â”‚   â”œâ”€â”€ ebird_client.py         # eBird integration
â”‚   â”‚   â”œâ”€â”€ xenocanto_client.py     # Xeno-Canto integration
â”‚   â”‚   â””â”€â”€ weather_client.py       # Weather API integration
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audio_features.py       # Audio feature extraction
â”‚   â”‚   â”œâ”€â”€ environmental_features.py # Environmental features
â”‚   â”‚   â””â”€â”€ stress_index.py         # Stress index calculation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lstm_model.py           # LSTM architecture
â”‚   â”‚   â”œâ”€â”€ vae_model.py            # VAE architecture
â”‚   â”‚   â””â”€â”€ trainer.py              # Training utilities
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”‚   â””â”€â”€ validators.py           # Data validation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ train.py                    # Training pipeline
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_features.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_model_evaluation.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ collect_data.py
â”‚   â”œâ”€â”€ process_features.py
â”‚   â””â”€â”€ deploy_model.py
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml              # Docker orchestration
â”œâ”€â”€ Dockerfile                      # Docker image
â”œâ”€â”€ pyproject.toml                  # Project metadata
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ setup.py                        # Package setup
â””â”€â”€ README.md                       # This file
```

---

## âš™ï¸ Configuration

### API Keys

Set in `.env` file:

```env
# eBird API
EBIRD_API_KEY=your_ebird_api_key_here

# Xeno-Canto API
XENO_CANTO_API_KEY=your_xenocanto_key_here

# OpenWeatherMap API
OPENWEATHER_API_KEY=your_openweather_key_here

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000

# Database (optional)
DATABASE_URL=postgresql://user:password@localhost:5432/bird_twin
```

### Model Hyperparameters

Edit `configs/config.yaml`:

- LSTM architecture
- VAE configuration
- Training parameters
- Feature extraction settings
- Data ingestion sources

---

## ğŸ³ Deployment

### Docker Deployment

```bash
# Build image
docker build -t bird-stress-twin:latest .

# Run container
docker run -d \
  -p 8000:8000 \
  --env-file .env \
  --name bird-twin-api \
  bird-stress-twin:latest
```

### Docker Compose (Recommended)

```bash
# Start all services
docker-compose up -d

# Services:
# - API: http://localhost:8000
# - MLflow: http://localhost:5000
# - PostgreSQL: localhost:5432

# View logs
docker-compose logs -f api

# Stop services
docker-compose down
```

### Cloud Deployment

**Google Cloud Run:**
```bash
gcloud run deploy bird-stress-twin \
  --image gcr.io/PROJECT_ID/bird-stress-twin \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

**AWS ECS:**
```bash
# Push to ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com
docker tag bird-stress-twin:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/bird-stress-twin:latest
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/bird-stress-twin:latest
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v --cov=src

# Run specific test
pytest tests/test_api.py -v

# Generate coverage report
pytest --cov=src --cov-report=html
```

---

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| **LSTM RÂ² Score** | 0.92 |
| **MAE** | 0.045 |
| **RMSE** | 0.063 |
| **API Latency** | <200ms |
| **Throughput** | 100+ req/s |

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **eBird** - Bird observation data
- **Xeno-Canto** - Bird audio recordings
- **OpenWeatherMap** - Environmental data
- **PyTorch** - Deep learning framework
- **FastAPI** - API framework
- **MLflow** - Experiment tracking

---

## ğŸ“§ Contact

For questions, issues, or collaborations:

- **Email**: your.email@example.com
- **GitHub**: [@yourusername](https://github.com/yourusername)
- **LinkedIn**: [Your Name](https://linkedin.com/in/yourname)

---

## ğŸŒŸ Star History

If this project helped you, please â­ star this repository!

---

**Made with â¤ï¸ for bird conservation and disaster preparedness**
# Digital-Bird-Stress-Twin
Real time avian stress monitoring(vocalization pattern) to predict the natural disasters also a virtual environment for avian species where a digital twin of birds are kept under certain atmostpheric condition to train the model that'll predict the Natural Disaster (Strom/Cyclone/flood)
